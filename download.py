from transformers import (
    AutoModel, AutoTokenizer, AutoModelForTokenClassification,
    CLIPVisionModel, CLIPImageProcessor
)
import os

def download_and_save_models():
    """
    ä¸‹è½½å¹¶ä¿å­˜æ¨¡åž‹åˆ°æœ¬åœ°ç›®å½•ï¼Œå¹¶ç”Ÿæˆ pytorch_model.binï¼š
    1. bert-base-chinese
    2. openai/clip-vit-base-patch32
    3. hfl/chinese-bert-wwm-ext
    """
    models_to_download = {
        # æ–‡æœ¬æ¨¡åž‹
        "bert-base-chinese": "models/bert-base-chinese",
        # å›¾åƒæ¨¡åž‹
        "openai/clip-vit-base-patch32": "models/clip-vit-base-patch32",
        # ä¸­æ–‡ NER æ¨¡åž‹
        "hfl/chinese-bert-wwm-ext": "models/chinese-bert-wwm-ext"
    }

    os.makedirs("models", exist_ok=True)

    # ===== ä¸‹è½½æ–‡æœ¬ BERT æ¨¡åž‹ =====
    bert_name = "bert-base-chinese"
    bert_dir = models_to_download[bert_name]
    os.makedirs(bert_dir, exist_ok=True)
    print(f"â³ æ­£åœ¨ä¸‹è½½æ–‡æœ¬æ¨¡åž‹ {bert_name} ...")
    bert_model = AutoModel.from_pretrained(bert_name)
    bert_tokenizer = AutoTokenizer.from_pretrained(bert_name)
    # ä¿å­˜ safetensors + pytorch_model.bin
    bert_model.save_pretrained(bert_dir, safe_serialization=False)
    bert_tokenizer.save_pretrained(bert_dir)
    print(f"âœ… æ–‡æœ¬æ¨¡åž‹ {bert_name} å·²ä¿å­˜åˆ° {bert_dir}")

    # ===== ä¸‹è½½å›¾åƒ CLIP æ¨¡åž‹ =====
    clip_name = "openai/clip-vit-base-patch32"
    clip_dir = models_to_download[clip_name]
    os.makedirs(clip_dir, exist_ok=True)
    print(f"â³ æ­£åœ¨ä¸‹è½½å›¾åƒæ¨¡åž‹ {clip_name} ...")
    clip_model = CLIPVisionModel.from_pretrained(clip_name)
    clip_processor = CLIPImageProcessor.from_pretrained(clip_name)
    clip_model.save_pretrained(clip_dir, safe_serialization=False)
    clip_processor.save_pretrained(clip_dir)
    print(f"âœ… å›¾åƒæ¨¡åž‹ {clip_name} å·²ä¿å­˜åˆ° {clip_dir}")

    # ===== ä¸‹è½½ä¸­æ–‡ NER æ¨¡åž‹ =====
    ner_name = "hfl/chinese-bert-wwm-ext"
    ner_dir = models_to_download[ner_name]
    os.makedirs(ner_dir, exist_ok=True)
    print(f"â³ æ­£åœ¨ä¸‹è½½ä¸­æ–‡ NER æ¨¡åž‹ {ner_name} ...")
    ner_model = AutoModelForTokenClassification.from_pretrained(ner_name)
    ner_tokenizer = AutoTokenizer.from_pretrained(ner_name)
    ner_model.save_pretrained(ner_dir, safe_serialization=False)
    ner_tokenizer.save_pretrained(ner_dir)
    print(f"âœ… ä¸­æ–‡ NER æ¨¡åž‹ {ner_name} å·²ä¿å­˜åˆ° {ner_dir}")

    print("ðŸŽ‰ æ‰€æœ‰æ¨¡åž‹å·²ä¸‹è½½å¹¶ç”Ÿæˆ pytorch_model.binï¼Œç›®å½•ç»“æž„å¦‚ä¸‹ï¼š")
    for k, v in models_to_download.items():
        print(f" - {k} -> {v}")

if __name__ == "__main__":
    download_and_save_models()
